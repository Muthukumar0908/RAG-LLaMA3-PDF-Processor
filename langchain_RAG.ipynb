{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208bf2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "import fitz\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde83fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your queries here... full name\n",
      "I'd be happy to help you extract the specific information requested. Here are the answers:\n",
      "\n",
      "**1. Full Name:** Augustine Rajesh\n",
      "\n",
      "**2. Email Address:** augustin.rajesh@ gmail.com\n",
      "\n",
      "**3. Phone Number:** 9840660196 (Mobile)\n",
      "\n",
      "**4. Education:**\n",
      "\n",
      "* NIIT, iGNIIT, Information Technology (2000-2002)\n",
      "* Karnataka University, M.Sc., Information Technology (2003-2005)\n",
      "* Pachaiyappas College, Bachelor of Commerce (B.Com.), Accounting and Commerce (1999-2002)\n",
      "* KCS Hr Sec School, +2, Business/Commerce, General (1992-1999)\n",
      "\n",
      "**5. Work Experience:**\n",
      "\n",
      "1. **Solution Architect**, March 2015 - Present (9 years 5 months)\n",
      "\t* Chennai\n",
      "2. **Senior Technical Architect**, April 2015 - March 2019 (4 years)\n",
      "3. **Technical Architect**, February 2010 - March 2015 (5 years 2 months)\n",
      "4. **Team Lead**, February 2008 - February 2010 (2 years 1 month)\n",
      "\t* Xchanging\n",
      "5. **Sr. Software Engineer**, September 2006 - February 2008 (1 year 6 months)\n",
      "\t* Satyam Computer services Limited\n",
      "6. **Sr. Software Engineer**, November 2004 - October 2006 (2 years)\n",
      "\t* Unlimited Innovations India Pvt Ltd\n",
      "7. **Programmer**, August 2003 - July 2004 (1 year)\n",
      "\t* EID Parry (INDIA) LTD\n",
      "8. **Web Designer**, June 2002 - July 2003 (1 year 2 months)\n",
      "\t* ESoft Factory Pvt Ltd\n",
      "\n",
      "**6. Technology / Tools Used:**\n",
      "\n",
      "* Microsoft .Net Framework 2.0 with C#\n",
      "* ASP .Net\n",
      "* Classic ASP\n",
      "* Visual Studio 2005\n",
      "* XML & XSLT\n",
      "* VSS\n",
      "* SQL Server 2005\n",
      "* SQL Server Reporting Service\n",
      "* SQL Server Business Intelligence\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "import pdfplumber\n",
    "\n",
    "pdf_path = r\"C:\\Users\\murugan\\Downloads\\Profile.pdf\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pages_text = [page.extract_text() for page in pdf.pages]\n",
    "    return \"\\n\".join(pages_text)\n",
    "\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "# print(pdf_text)\n",
    "input_txt = input(\"Please enter your queries here... \")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Using the uploaded resume, please extract and provide the specific information requested below:\n",
    "\n",
    "1. Full Name: Only the full name.\n",
    "2. Email Address: Only the email address.\n",
    "3. Phone Number: Only the phone number.\n",
    "4. Full Address: Only the full address.\n",
    "5. Educational Background: Only the education details.\n",
    "6. Detailed Work Experience: Only the work experience.\n",
    "7. Technical Skills: Only the technical skills.\n",
    "8. Current or Recent Job Title: Only the job title.\n",
    "9. Current or Recent Employer: Only the employer's name.\n",
    "10. Detailed Work Experience: Only the work experience details.\n",
    "11. Skills Summary: Only the skills.\n",
    "12. Certifications: Only the certifications.\n",
    "13. Projects: Only the projects details.\n",
    "14. Notable Achievements: Only the achievements.\n",
    "15. Languages Spoken: Only the languages.\n",
    "16. References: Only the references.\n",
    "17. Professional Summary: Only the professional summary.\n",
    "\n",
    "Answer the all question, each in a separate response, providing just the specific information requested.\n",
    "\"\"\"),\n",
    "    (\"user\", f\"User query: {input_txt}\"),\n",
    "    (\"user\", f\"Resume text: {pdf_text}\")\n",
    "])\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "\n",
    "if input_txt:\n",
    "    data = chain.invoke({\"query\": input_txt, \"pdf_text\": pdf_text})\n",
    "# data = chain.invoke({\"pdf_text\": pdf_text})\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2e437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f196d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496354f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "646334e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your queries here... 1. provide the all educational qualification?\n",
      "Output: Here are the educational qualifications mentioned in the resume:\n",
      "\n",
      "1. iGNIIT, Information Technology (2000 - 2002)\n",
      "2. M.Sc, Information Technology (2003 - 2005), Karnataka University\n",
      "3. Bachelor of Commerce (B.Com.), Accounting and Commerce (1999 - 2002), Pachaiyappas College\n",
      "4. +2, Business/Commerce, General (1992 - 1999), KCS Hr Sec School\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_path = r\"C:\\Users\\murugan\\Downloads\\Profile.pdf\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pages_text = [page.extract_text() for page in pdf.pages]\n",
    "    return \"\\n\".join(pages_text)\n",
    "\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "# print(\"PDF text:\", pdf_text)\n",
    "\n",
    "input_txt = input(\"Please enter your queries here... \")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"When asked a question, provide a relevant answer directly and precisely.\"),\n",
    "    (\"user\", f\"User query: {input_txt}\"),\n",
    "    (\"user\", f\"Resume text: {pdf_text}\")\n",
    "])\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "if input_txt:\n",
    "    data = chain.invoke({\"query\": input_txt, \"pdf_text\": pdf_text})\n",
    "    print(\"Output:\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72330f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4306a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "151da63e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "InMemoryChatMessageHistory.add_message() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Add initial context to memory\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m initial_messages:\n\u001b[1;32m---> 35\u001b[0m     memory\u001b[38;5;241m.\u001b[39mchat_memory\u001b[38;5;241m.\u001b[39madd_message(msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m], msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Get user input\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     input_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter your queries here... (or type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: InMemoryChatMessageHistory.add_message() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pages_text = [page.extract_text() for page in pdf.pages]\n",
    "    return \"\\n\".join(pages_text)\n",
    "\n",
    "# Extract text from the PDF\n",
    "pdf_path = r\"C:\\Users\\murugan\\Downloads\\Profile.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Initialize LLM\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Memory for conversation\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "# Initial system message and PDF content\n",
    "initial_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"When asked a question, provide a relevant answer directly and precisely.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Resume text: {pdf_text}\"}\n",
    "]\n",
    "\n",
    "# Add initial context to memory\n",
    "for msg in initial_messages:\n",
    "    memory.chat_memory.add_message(msg[\"role\"], msg[\"content\"])\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    input_txt = input(\"Please enter your queries here... (or type 'exit' to quit): \")\n",
    "\n",
    "    if input_txt.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Add user query to memory\n",
    "    memory.chat_memory.add_message(\"user\", input_txt)\n",
    "\n",
    "    # Load memory messages\n",
    "    past_messages = memory.chat_memory.messages\n",
    "\n",
    "    # Create prompt template with memory\n",
    "    prompt = ChatPromptTemplate.from_messages(past_messages)\n",
    "\n",
    "    # Create chain\n",
    "    chain = LLMChain(prompt=prompt, llm=llm, output_parser=output_parser)\n",
    "\n",
    "    # Invoke chain with input query\n",
    "    response = chain.invoke({\"input\": input_txt})\n",
    "\n",
    "    # Add model response to memory\n",
    "    memory.chat_memory.add_message(\"assistant\", response)\n",
    "\n",
    "    print(\"Output:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58706e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fee72296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b9663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c044d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234b08c6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your queries here... (or type 'exit' to quit): what is the candidate name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: {'query': 'what is the candidate name?', 'pdf_text': 'Contact Augustine Rajesh\\nAdyar, Chennai.\\n9840660196 (Mobile) CIB 2S Central Architect @ BNP Paribas | Technology Leadership\\naugustin.rajesh@gmail.com Chennai, Tamil Nadu, India\\nwww.linkedin.com/in/\\naugustinerajesh (LinkedIn) Summary\\nI am a Central (Enterprise) Architect at BNP Paribas, with over 19\\nTop Skills\\nyears of progressive technical leadership experience and passion for\\nTechnology Leadership\\ntechnology. I have expertise in several technologies, such as cloud,\\nReliability\\nAI, LLM, Blockchain, .NET, Java, Python, and NodeJS, and I have\\nIndustry standards\\nworked in multiple domains, such as banking, capital markets, supply\\nchain, healthcare, and e-commerce.\\nLanguages\\nTamil\\nMy mission is to provide/validate the solutions to the new and\\nGerman (Elementary)\\nexisting applications for the APAC and ANZ regions, ensuring\\nGerman (Elementary)\\ninformation system consistency, communication, and support to local\\nEnglish\\nteams, cloud assessment and architecture board setup. I have a\\nproven track record of delivering innovative and efficient solutions,\\nCertifications\\nobtaining buy-in from sponsors, defining technical requirements,\\nCorda Certified Developer\\nconsulting during development and deployment, and monitoring\\nCloud Architecture Bronze\\nand management. I am always eager to learn new technologies and\\nMicrosoft Certified Application\\nDeveloper (MCAD) experiment with them to come up with creative solutions. I am also a\\nBNP Paribas Cloud 101 go-to person for my onshore and offshore stakeholders, thanks to my\\nvast knowledge, networking skills, and commitment.\\nHonors-Awards\\nPat on the Back Award from\\nXchanging Experience\\nOutstanding performance award\\nAward of Excellence BNP Paribas\\n14 years 6 months\\nCIB 2S Central (Enterprise) Architect\\nOctober 2021 - Present (2 years 10 months)\\nChennai, Tamil Nadu, India\\nI will be in charge of BP2S Central Architecture for all APAC Project. I will\\nensure information system consistency with application portfolio managers and\\naddress the following topics.\\n* Support and Control activities\\n* Provide Communication and support to local teams on EA Process\\n* Could Assessment\\nPage 1 of 5\\n* Setup a local architecture board\\n* Obsolescence Management\\n* Application Portfolio Reviews\\nPrincipal Technical Architect, AVP\\nMarch 2019 - Present (5 years 5 months)\\nChennai Area, India\\nHeading the Architecture team in Chennai and my overall responsibility is to\\nprovide Solutions to the new / existing systems for both Australia and New\\nZealand\\nregion.\\n• Work as a consultative fashion with other functional heads / SMEs as an\\nadvisor of technologies that improves the efficiency and effectiveness.\\n• Balance functionality, requirements and business needs.\\n• Preparing Technical solution and architecture documents, artifacts, work\\nproducts and presentations for the clients.\\n• Obtain buy-in from the sponsors.\\n• Defining the technical requirements for the implementation and integration of\\nvarious systems.\\n• Consult during development and deployment.\\n• Monitoring and management.\\n• Global System Integrations with proper impact assessment.\\n• Design the scalable solutions.\\n• Discussing technical aspects of the application solution architecture,\\nincluding technology used, methodology followed and to make it generic or\\ncustomized for different clients.\\n• Present the solution in the architecture review board and get the sign-off.\\n• Develop reusable artifacts/frameworks, reference architecture design and\\nbest practice.\\n• Responsible for successfully design and managing the delivery of solutions\\nand technologies.\\n• Analyse emerging technologies and make recommendations for\\nadaptation.\\n• Playing pivotal role in the Digital Transformation portfolio project initiatives.\\n• Build and maintain working relationship with the top management, project\\ndelivery and service management people.\\n• Work both independently and with all levels of the organization, including\\ntechnical and business/operations (not-technical) team members.\\n• Act as a bridge between business and technology team.\\nPage 2 of 5\\n• Coach and mentor the junior members in the organization.\\n• Generate technology awareness.\\nSolution Architect\\nMarch 2015 - Present (9 years 5 months)\\nChennai\\nSenior Technical Architect\\nApril 2015 - March 2019 (4 years)\\nTechnical Architect\\nFebruary 2010 - March 2015 (5 years 2 months)\\nChennai\\nXchanging\\nTeam Lead\\nFebruary 2008 - February 2010 (2 years 1 month)\\nTechnical Lead in the Framework and Product development team and involved\\nin requirement Analysis, built reusable components using C#, built prototypes,\\nR & D, peer reviews, client communication and participated in the technical\\ndiscussions with Architects.\\nSatyam Computer services Limited\\nSr. Software Engineer\\nSeptember 2006 - February 2008 (1 year 6 months)\\nWhen I was associated with Satyam Computes, I got a chance to work for\\none of the major banking giant Merrill Lynch. As a Senior developer I have\\ninvolved in a project called Research Library. I am a senior developer and\\ninvolved in all the development phases of the project from the scratch. I have\\nintroduced the asynchronous call using java script in this project and improved\\nthe performance and user experience of the website.\\nLed development Team, Analysis, Programming, Testing, Review,\\nImplementation, Client Communications and Group discussions are the key\\nroles and responsibilities.\\nUnlimited Innovations India Pvt Ltd\\nSr. Software Engineer\\nNovember 2004 - October 2006 (2 years)\\nChennai, India\\nPage 3 of 5\\nUnlimited Innovations (UI) was a Indian start-up company and I had joined as\\na first employee.\\nI was joined as first developer in this product development company. I have\\nplayed a major role in the initial growth, helped my organization to grow up to\\n20+ employees within one year timeframe. I have also built a core technical\\nteam in Chennai and delivered more number of projects in a short span\\nin time. Built more trust and confidence on the offshore team with the US\\nmanagement, which helped us bring more projects to Chennai.\\nTechnology / Tools Used:\\n* Microsoft .Net Framework 2.0 with C#\\n* ASP .Net\\n* Classic ASP\\n* Visual Studio 2005\\n* XML & XSLT\\n* VSS\\n* SQL Server 2005\\n* SQL Server Reporting Service\\n* SQL Server Business Intelligence\\nEID PARRY (INDIA) LTD\\nProgrammer\\nAugust 2003 - July 2004 (1 year)\\nChennai Area, India\\nAs part of NIIT job placement, I got a chance to work with EID Parry. I was\\na programmer and provided end to end support for all the development\\nand support activities to their in-house Accounting, Payroll and Security\\napplications. I was also responsible for Server maintenance, Patch Updates,\\nregular data backup in Tape Drive, SAP application support for users who are\\nworking in the factory plant.\\nESoft Factory Pvt Ltd\\nWeb Designer\\nJune 2002 - July 2003 (1 year 2 months)\\nChennai Area, India\\nAfter my graduation, I have started my career as a junior programmer and Web\\nDesigner in ESoft.\\nPage 4 of 5\\nEducation\\nNIIT\\niGNIIT, Information Technology · (2000 - 2002)\\nKarnataka Unversity\\nM.Sc, Information Technology · (2003 - 2005)\\nPachaiyappas College\\nBachelor of Commerce (B.Com.), Accounting and Commerce · (1999 - 2002)\\nKCS Hr Sec School\\n+2, Business/Commerce, General · (1992 - 1999)\\nPage 5 of 5', 'text': \"The candidate's name is Augustine Rajesh.\"}\n",
      "Please enter your queries here... (or type 'exit' to quit): quit\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     21\u001b[0m chat_history\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 22\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(chat_history)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# chain\u001b[39;00m\n\u001b[0;32m     25\u001b[0m chain \u001b[38;5;241m=\u001b[39m LLMChain(prompt\u001b[38;5;241m=\u001b[39mprompt, llm\u001b[38;5;241m=\u001b[39mllm, output_parser\u001b[38;5;241m=\u001b[39moutput_parser)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:969\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_messages\u001b[1;34m(cls, messages, template_format)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    932\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[0;32m    933\u001b[0m     template_format: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmustache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[0;32m    935\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \n\u001b[0;32m    937\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;124;03m        a chat prompt template\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    970\u001b[0m         _convert_to_message(message, template_format) \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[0;32m    971\u001b[0m     ]\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     input_vars: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:970\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_messages\u001b[39m(\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    932\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[0;32m    933\u001b[0m     template_format: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmustache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf-string\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatPromptTemplate:\n\u001b[0;32m    935\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \n\u001b[0;32m    937\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;124;03m        a chat prompt template\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    969\u001b[0m     _messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 970\u001b[0m         _convert_to_message(message, template_format) \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[0;32m    971\u001b[0m     ]\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;66;03m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     input_vars: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:1226\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[1;34m(message, template_format)\u001b[0m\n\u001b[0;32m   1224\u001b[0m message_type_str, template \u001b[38;5;241m=\u001b[39m message\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message_type_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1226\u001b[0m     _message \u001b[38;5;241m=\u001b[39m _create_template_from_message_type(\n\u001b[0;32m   1227\u001b[0m         message_type_str, template, template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[0;32m   1228\u001b[0m     )\n\u001b[0;32m   1229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1230\u001b[0m     _message \u001b[38;5;241m=\u001b[39m message_type_str(\n\u001b[0;32m   1231\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m   1232\u001b[0m             cast(\u001b[38;5;28mstr\u001b[39m, template), template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[0;32m   1233\u001b[0m         )\n\u001b[0;32m   1234\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:1146\u001b[0m, in \u001b[0;36m_create_template_from_message_type\u001b[1;34m(message_type, template, template_format)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     message: BaseMessagePromptTemplate \u001b[38;5;241m=\u001b[39m HumanMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m   1143\u001b[0m         template, template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m message_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1146\u001b[0m     message \u001b[38;5;241m=\u001b[39m AIMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m   1147\u001b[0m         cast(\u001b[38;5;28mstr\u001b[39m, template), template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[0;32m   1148\u001b[0m     )\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m message_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1150\u001b[0m     message \u001b[38;5;241m=\u001b[39m SystemMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[0;32m   1151\u001b[0m         cast(\u001b[38;5;28mstr\u001b[39m, template), template_format\u001b[38;5;241m=\u001b[39mtemplate_format\n\u001b[0;32m   1152\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:476\u001b[0m, in \u001b[0;36m_StringImageMessagePromptTemplate.from_template\u001b[1;34m(cls, template, template_format, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(prompt\u001b[38;5;241m=\u001b[39mprompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 476\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[1;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pages_text = [page.extract_text() for page in pdf.pages]\n",
    "    return \"\\n\".join(pages_text)\n",
    "\n",
    "pdf_path = r\"C:\\Users\\murugan\\Downloads\\Profile.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Initialize chat history\n",
    "chat_history = [(\"system\", \"When asked a question, provide a relevant answer directly and precisely.\"),\n",
    "                (\"user\", f\"Resume text: {pdf_text}\")]\n",
    "\n",
    "while True:\n",
    "    input_txt = input(\"Please enter your queries here... (or type 'exit' to quit): \")\n",
    "\n",
    "    if input_txt.lower() == 'exit':\n",
    "        break\n",
    "    chat_history.append((\"user\", f\"User query: {input_txt}\"))\n",
    "    prompt = ChatPromptTemplate.from_messages(chat_history)\n",
    "\n",
    "    # chain\n",
    "    chain = LLMChain(prompt=prompt, llm=llm, output_parser=output_parser)\n",
    "\n",
    "    data = chain.invoke({\"query\": input_txt, \"pdf_text\": pdf_text})\n",
    "\n",
    "    # Add model response to chat history\n",
    "    chat_history.append((\"assistant\", data))\n",
    "\n",
    "    print(\"Output:\", data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035c623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0783711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb5110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da3e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08baca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4abcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d1c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48e686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d8a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c9e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f8d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5dddc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17b279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdc90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f008da1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StroutputParser' from 'langchain_core.output_parsers' (C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StroutputParser\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ollama\n\u001b[0;32m      6\u001b[0m input_txt \u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enter your queries here...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StroutputParser' from 'langchain_core.output_parsers' (C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StroutputParser\n",
    "from langchain_community.llms import ollama\n",
    "\n",
    "\n",
    "input_txt =input(\"Please enter your queries here...\")\n",
    "prompt = ChatPromptTemplate.from_messages (\n",
    "                [(\"system\", \"you are a helpful AI assistant. Your name is Karthik's Assistant\"), (\"user\", \"user query: {query}\")\n",
    "                ])\n",
    "llm = Ollama (model=\"llama3\")\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "if input_txt:\n",
    "    data=chain.invoke({\"query\":input_txt})\n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d1fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed21327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4169b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fda739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4da6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88e502cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement lanchain_core (from versions: none)\n",
      "ERROR: No matching distribution found for lanchain_core\n"
     ]
    }
   ],
   "source": [
    "!pip install lanchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6bbd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\murugan\\anaconda3\\lib\\site-packages (24.1.1)\n",
      "Collecting pip\n",
      "  Using cached pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.1.2-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "c:\\Users\\murugan\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b14a75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8ab09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8a6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac75eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4deab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395592be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead20687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94853f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f64ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111accd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71bcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6218a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb57e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b8e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38483bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a1c9559f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import fitz \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca240590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(base_url='http://localhost:11434', model='llama2', embed_instruction='passage: ', query_instruction='query: ', mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None, show_progress=False, headers=None, model_kwargs=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.ollama.OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chroma.from_documents(documents=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be5d91fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Collection' object has no attribute 'model_fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m langchain_documents\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#second step\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m     20\u001b[0m     documents\u001b[38;5;241m=\u001b[39mlangchain_documents,\n\u001b[0;32m     21\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag-chroma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membeddings\u001b[38;5;241m.\u001b[39mollama\u001b[38;5;241m.\u001b[39mOllamaEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnomic-embed-text\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:790\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    789\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    791\u001b[0m     texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    792\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    793\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    794\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    795\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    796\u001b[0m     persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    797\u001b[0m     client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    798\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    799\u001b[0m     collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    801\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:726\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    706\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[0;32m    707\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 726\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    727\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    728\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m    729\u001b[0m         persist_directory\u001b[38;5;241m=\u001b[39mpersist_directory,\n\u001b[0;32m    730\u001b[0m         client_settings\u001b[38;5;241m=\u001b[39mclient_settings,\n\u001b[0;32m    731\u001b[0m         client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m    732\u001b[0m         collection_metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    733\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    734\u001b[0m     )\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m         ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:127\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persist_directory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    123\u001b[0m         _client_settings\u001b[38;5;241m.\u001b[39mpersist_directory \u001b[38;5;129;01mor\u001b[39;00m persist_directory\n\u001b[0;32m    124\u001b[0m     )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;241m=\u001b[39m embedding_function\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mget_or_create_collection(\n\u001b[0;32m    128\u001b[0m     name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m    129\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    130\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mcollection_metadata,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_relevance_score_fn \u001b[38;5;241m=\u001b[39m relevance_score_fn\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\client.py:166\u001b[0m, in \u001b[0;36mClient.get_or_create_collection\u001b[1;34m(self, name, configuration, metadata, embedding_function, data_loader)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_or_create_collection\u001b[39m(\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m     data_loader: Optional[DataLoader[Loadable]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    165\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 166\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server\u001b[38;5;241m.\u001b[39mget_or_create_collection(\n\u001b[0;32m    167\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    168\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    169\u001b[0m         tenant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtenant,\n\u001b[0;32m    170\u001b[0m         database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    171\u001b[0m         configuration\u001b[38;5;241m=\u001b[39mconfiguration,\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Collection(\n\u001b[0;32m    174\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server,\n\u001b[0;32m    175\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    176\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function,\n\u001b[0;32m    177\u001b[0m         data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\segment.py:221\u001b[0m, in \u001b[0;36mSegmentAPI.get_or_create_collection\u001b[1;34m(self, name, configuration, metadata, tenant, database)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSegmentAPI.get_or_create_collection\u001b[39m\u001b[38;5;124m\"\u001b[39m, OpenTelemetryGranularity\u001b[38;5;241m.\u001b[39mOPERATION\n\u001b[0;32m    211\u001b[0m )\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CollectionModel:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_collection(\n\u001b[0;32m    222\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    223\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    224\u001b[0m         configuration\u001b[38;5;241m=\u001b[39mconfiguration,\n\u001b[0;32m    225\u001b[0m         get_or_create\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    226\u001b[0m         tenant\u001b[38;5;241m=\u001b[39mtenant,\n\u001b[0;32m    227\u001b[0m         database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\api\\segment.py:176\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[1;34m(self, name, configuration, metadata, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    164\u001b[0m model \u001b[38;5;241m=\u001b[39m CollectionModel(\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m    166\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# TODO: Let sysdb create the collection directly from the model\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sysdb\u001b[38;5;241m.\u001b[39mcreate_collection(\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    178\u001b[0m     name\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    179\u001b[0m     configuration\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_configuration(),\n\u001b[0;32m    180\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[0;32m    181\u001b[0m     dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# This is lazily populated on the first add\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     get_or_create\u001b[38;5;241m=\u001b[39mget_or_create,\n\u001b[0;32m    183\u001b[0m     tenant\u001b[38;5;241m=\u001b[39mtenant,\n\u001b[0;32m    184\u001b[0m     database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[0;32m    185\u001b[0m )\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# TODO: wrap sysdb call in try except and log error if it fails\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:146\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\db\\mixins\\sysdb.py:255\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[1;34m(self, id, name, configuration, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    241\u001b[0m collections \u001b[38;5;241m=\u001b[39m Table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollections\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    242\u001b[0m databases \u001b[38;5;241m=\u001b[39m Table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabases\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m insert_collection \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquerybuilder()\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;241m.\u001b[39minto(collections)\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;241m.\u001b[39mcolumns(\n\u001b[0;32m    248\u001b[0m         collections\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    249\u001b[0m         collections\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    250\u001b[0m         collections\u001b[38;5;241m.\u001b[39mconfig_json_str,\n\u001b[0;32m    251\u001b[0m         collections\u001b[38;5;241m.\u001b[39mdimension,\n\u001b[0;32m    252\u001b[0m         collections\u001b[38;5;241m.\u001b[39mdatabase_id,\n\u001b[0;32m    253\u001b[0m     )\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m--> 255\u001b[0m         ParameterValue(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muuid_to_db(collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])),\n\u001b[0;32m    256\u001b[0m         ParameterValue(collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    257\u001b[0m         ParameterValue(configuration\u001b[38;5;241m.\u001b[39mto_json_str()),\n\u001b[0;32m    258\u001b[0m         ParameterValue(collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;66;03m# Get the database id for the database with the given name and tenant\u001b[39;00m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquerybuilder()\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;241m.\u001b[39mselect(databases\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;241m.\u001b[39mfrom_(databases)\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;241m.\u001b[39mwhere(databases\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m ParameterValue(database))\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;241m.\u001b[39mwhere(databases\u001b[38;5;241m.\u001b[39mtenant_id \u001b[38;5;241m==\u001b[39m ParameterValue(tenant)),\n\u001b[0;32m    265\u001b[0m     )\n\u001b[0;32m    266\u001b[0m )\n\u001b[0;32m    267\u001b[0m sql, params \u001b[38;5;241m=\u001b[39m get_sql(insert_collection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter_format())\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\chromadb\\types.py:99\u001b[0m, in \u001b[0;36mCollection.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_configuration()\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# For the other model attributes we allow the user to access them directly\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_fields:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Collection' object has no attribute 'model_fields'"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# model_local = ChatOllama(model=\"llama3\")\n",
    "#first step\n",
    "pdf_path = \"C:/Users/murugan/Downloads/Muthukumar.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "documents = text_splitter.split_text(pdf_text)\n",
    "langchain_documents = [Document(page_content=doc) for doc in documents]\n",
    "langchain_documents\n",
    "\n",
    "#second step\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=langchain_documents,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings.ollama.OllamaEmbeddings(model='nomic-embed-text'),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3552181",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\murugan\\anaconda3\\lib\\site-packages (0.1.17)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\murugan\\anaconda3\\lib\\site-packages (0.0.38)\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: chromadb in c:\\users\\murugan\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Collecting langchain-core<0.3.0,>=0.2.12 (from langchain)\n",
      "  Downloading langchain_core-0.2.13-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (0.1.56)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.6)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.5 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (0.7.5)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (0.111.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (1.18.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (1.64.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (4.1.3)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (3.10.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (3.1.3)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (5.4.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.85-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (13.3.5)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Using cached langchain-0.2.7-py3-none-any.whl (983 kB)\n",
      "Using cached langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
      "Downloading langchain_core-0.2.13-py3-none-any.whl (357 kB)\n",
      "   ---------------------------------------- 0.0/357.9 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 327.7/357.9 kB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 357.9/357.9 kB 7.4 MB/s eta 0:00:00\n",
      "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.85-py3-none-any.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.9/127.9 kB 7.4 MB/s eta 0:00:00\n",
      "Installing collected packages: langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.56\n",
      "    Uninstalling langsmith-0.1.56:\n",
      "      Successfully uninstalled langsmith-0.1.56\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.52\n",
      "    Uninstalling langchain-core-0.1.52:\n",
      "      Successfully uninstalled langchain-core-0.1.52\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.1\n",
      "    Uninstalling langchain-text-splitters-0.0.1:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.17\n",
      "    Uninstalling langchain-0.1.17:\n",
      "      Successfully uninstalled langchain-0.1.17\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "Successfully installed langchain-0.2.7 langchain-core-0.2.13 langchain-text-splitters-0.2.2 langchain_community-0.2.7 langsmith-0.1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-groq 0.1.3 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.2.13 which is incompatible.\n",
      "langchain-openai 0.1.6 requires langchain-core<0.2.0,>=0.1.46, but you have langchain-core 0.2.13 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain langchain_community chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f899f51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc714b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `RetrievalQA` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use create_retrieval_chain instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for RetrievalQA\ncombine_documents_chain\n  field required (type=value_error.missing)\nretriever\n  value is not a valid dict (type=type_error.dict)\nllm\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m llm \u001b[38;5;241m=\u001b[39m Ollama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Create a RetrievalQA chain\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA(llm\u001b[38;5;241m=\u001b[39mllm, retriever\u001b[38;5;241m=\u001b[39mdocsearch)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the question: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:183\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     emit_warning()\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for RetrievalQA\ncombine_documents_chain\n  field required (type=value_error.missing)\nretriever\n  value is not a valid dict (type=type_error.dict)\nllm\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document  # Importing Document from schema\n",
    "\n",
    "# Function to load and split PDF content into chunks\n",
    "def load_and_split_pdf(pdf_path):\n",
    "    docs = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                chunks = text_splitter.split_text(page_text)\n",
    "                for chunk in chunks:\n",
    "                    docs.append(Document(page_content=chunk))\n",
    "    return docs\n",
    "\n",
    "# Paths to PDF files\n",
    "pdf_paths = [r\"C:\\Users\\murugan\\Downloads\\Muthukumar.pdf\"]\n",
    "\n",
    "# Load and split PDF content into chunks\n",
    "docs = []\n",
    "for pdf_path in pdf_paths:\n",
    "    docs.extend(load_and_split_pdf(pdf_path))\n",
    "\n",
    "# Create embeddings for document chunks using SentenceTransformer\n",
    "embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "docsearch = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "qa = RetrievalQA(llm=llm, retriever=docsearch)\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter the question: \")\n",
    "    if question.lower() == \"exit\":\n",
    "        print(\"The End\")\n",
    "        break\n",
    "    if question == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Generate answer using the RAG method\n",
    "    result = qa.run(question)\n",
    "    print(\"Answer:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1aaa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `RetrievalQA` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use create_retrieval_chain instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for RetrievalQA\ncombine_documents_chain\n  field required (type=value_error.missing)\nretriever\n  field required (type=value_error.missing)\ndocuments\n  extra fields not permitted (type=value_error.extra)\nembeddings\n  extra fields not permitted (type=value_error.extra)\nllm\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m llm \u001b[38;5;241m=\u001b[39m Ollama(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Create a RetrievalQA chain\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQA(llm\u001b[38;5;241m=\u001b[39mllm, documents\u001b[38;5;241m=\u001b[39mdocs, embeddings\u001b[38;5;241m=\u001b[39membedding)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the question: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:183\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     emit_warning()\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 5 validation errors for RetrievalQA\ncombine_documents_chain\n  field required (type=value_error.missing)\nretriever\n  field required (type=value_error.missing)\ndocuments\n  extra fields not permitted (type=value_error.extra)\nembeddings\n  extra fields not permitted (type=value_error.extra)\nllm\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Function to load and split PDF content into chunks\n",
    "def load_and_split_pdf(pdf_path):\n",
    "    docs = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                chunks = text_splitter.split_text(page_text)\n",
    "                for chunk in chunks:\n",
    "                    docs.append(Document(page_content=chunk))\n",
    "    return docs\n",
    "\n",
    "# Paths to PDF files\n",
    "pdf_paths = [r\"C:\\Users\\murugan\\Downloads\\Muthukumar.pdf\"]\n",
    "\n",
    "# Load and split PDF content into chunks\n",
    "docs = []\n",
    "for pdf_path in pdf_paths:\n",
    "    docs.extend(load_and_split_pdf(pdf_path))\n",
    "\n",
    "# Create embeddings for document chunks using SentenceTransformer\n",
    "embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "qa = RetrievalQA(llm=llm, documents=docs, embeddings=embedding)\n",
    "\n",
    "while True:\n",
    "    question = input(\"Enter the question: \")\n",
    "    if question.lower() == \"exit\":\n",
    "        print(\"The End\")\n",
    "        break\n",
    "    if question == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Generate answer using the RetrievalQA chain\n",
    "    result = qa.run(question)\n",
    "    print(\"Answer:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0623658",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "incomplete escape \\U at position 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall -c conda-forge faiss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:30\u001b[0m, in \u001b[0;36mis_conda_environment.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:128\u001b[0m, in \u001b[0;36mPackagingMagics.conda\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;129m@line_magic\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;129m@is_conda_environment\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconda\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the conda package manager within the current kernel.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Usage:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m      %conda install [pkgs]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     conda \u001b[38;5;241m=\u001b[39m _get_conda_like_executable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_command(conda, line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:53\u001b[0m, in \u001b[0;36m_get_conda_like_executable\u001b[1;34m(command)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Otherwise, attempt to extract the executable from conda history.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# This applies in any conda environment.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m history \u001b[38;5;241m=\u001b[39m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^#\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*cmd:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(?P<command>.*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms[create|install]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     history,\n\u001b[0;32m     56\u001b[0m     flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mMULTILINE,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroupdict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:176\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:294\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    293\u001b[0m               \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 294\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:989\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    986\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    987\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 989\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    990\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:464\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    462\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    465\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:872\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    869\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    870\u001b[0m sub_verbose \u001b[38;5;241m=\u001b[39m ((verbose \u001b[38;5;129;01mor\u001b[39;00m (add_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    871\u001b[0m                \u001b[38;5;129;01mnot\u001b[39;00m (del_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[1;32m--> 872\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m source\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing ), unterminated subpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    875\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:464\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    462\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    465\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:548\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 548\u001b[0m     code \u001b[38;5;241m=\u001b[39m _escape(source, this, state)\n\u001b[0;32m    549\u001b[0m     subpatternappend(code)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPECIAL_CHARS:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:402\u001b[0m, in \u001b[0;36m_escape\u001b[1;34m(source, escape, state)\u001b[0m\n\u001b[0;32m    400\u001b[0m escape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mgetwhile(\u001b[38;5;241m8\u001b[39m, HEXDIGITS)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincomplete escape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m escape, \u001b[38;5;28mlen\u001b[39m(escape))\n\u001b[0;32m    403\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(escape[\u001b[38;5;241m2\u001b[39m:], \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28mchr\u001b[39m(c) \u001b[38;5;66;03m# raise ValueError for invalid code\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: incomplete escape \\U at position 28"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5361d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\murugan\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.40.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\murugan\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1132b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\murugan\\anaconda3\\lib\\site-packages (24.1.1)\n",
      "Collecting pip\n",
      "  Using cached pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "Successfully installed pip-24.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.11.exe and pip3.exe are installed in 'C:\\Users\\murugan\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --user --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519421e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\murugan\\appdata\\roaming\\python\\python311\\site-packages (24.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19489a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

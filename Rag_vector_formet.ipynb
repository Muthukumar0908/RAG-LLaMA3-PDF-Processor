{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb6064d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc14af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa61988",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_in_executor' from 'langchain_core.runnables' (C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OllamaEmbeddings\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\document_loaders\\__init__.py:192\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m         AcreomLoader,\n\u001b[0;32m     25\u001b[0m         AirbyteCDKLoader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m         YuqueLoader,\n\u001b[0;32m    190\u001b[0m     )\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blob, BlobLoader\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# For backwards compatibility\u001b[39;00m\n\u001b[0;32m    195\u001b[0m _old_to_new_name \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPagedPDFSplitter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyPDFLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelegramChatLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelegramChatFileLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseBlobParser, BaseLoader\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblob_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blob, BlobLoader, PathLike\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseBlobParser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPathLike\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, AsyncIterator, Iterator, List, Optional\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_in_executor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextSplitter\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'run_in_executor' from 'langchain_core.runnables' (C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load PDF document\n",
    "loader = PyPDFLoader(\"C:/Users/murugan/Downloads/Muthukumar.pdf\")\n",
    "pages_content = loader.load_and_split()\n",
    "\n",
    "# Define the text splitter with chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# Split the documents into chunks\n",
    "documents = text_splitter.split_documents(pages_content)\n",
    "\n",
    "# Initialize the embeddings model\n",
    "ollama_emb = OllamaEmbeddings(model=\"llama3\")\n",
    "\n",
    "# Create the FAISS vector store\n",
    "vector = FAISS.from_documents(documents, ollama_emb)\n",
    "\n",
    "# Create the retriever\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Define the system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Only send me the default answer.\"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the document chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the retrieval chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# Custom Memory Class\n",
    "class CustomMemory:\n",
    "    def __init__(self):\n",
    "        self.history = \"\"\n",
    "\n",
    "    def add_to_history(self, interaction):\n",
    "        self.history += interaction + \"\\n\"\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "\n",
    "# Initialize custom memory\n",
    "memory = CustomMemory()\n",
    "\n",
    "# Create the main chain function\n",
    "def ask_question(question):\n",
    "    # Add the current question to history\n",
    "    memory.add_to_history(f\"Question: {question}\")\n",
    "    \n",
    "    # Invoke the chain\n",
    "    response = retrieval_chain.invoke({\n",
    "        \"input\": question,\n",
    "        \"context\": \"\",  # Provide additional context if needed\n",
    "        \"history\": memory.get_history()\n",
    "    })\n",
    "    \n",
    "    # Add the response to history\n",
    "    memory.add_to_history(f\"Answer: {response['answer']}\")\n",
    "    \n",
    "    # Print the answer\n",
    "    print(response[\"answer\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e299f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Muthukumar R'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = conversational_chain({\"question\": \"what is the name of the candidate? only name\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0eb0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided context, the name of the candidate is MUTHUKUMAR R.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = conversational_chain({\"question\": \"tell me the previous question\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe1f634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Muthukumar R.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"name of the candidate?\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79253902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Memory Summary:\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# Initialize the memory with summary capabilities\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    max_token_limit=100,  # Adjust this value as needed\n",
    "    llm=llm  # Use the same language model for summarization\n",
    ")\n",
    "\n",
    "# ... (rest of the code remains the same)\n",
    "\n",
    "# In the main loop, replace the memory output section with:\n",
    "print(\"\\nCurrent Memory Summary:\")\n",
    "print(memory.load_memory_variables({})[\"chat_history\"])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main interaction loop\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Chat with the AI. Type 'exit', 'quit', or 'bye' to end the conversation.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"AI: Goodbye!\")\n",
    "            break\n",
    "        response = get_response(user_input)\n",
    "        print(\"AI:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab61315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27594cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71508e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd342e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda7beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "176f3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8985d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usagex\n",
    "question1 = \"What is the summary of the first part of the document?\"\n",
    "response1 = handle_question(question1)\n",
    "print(response1)\n",
    "\n",
    "question2 = \"Can you give me more details about the second part?\"\n",
    "response2 = handle_question(question2)\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90805edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041f601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMChain(llm=llm,memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe527d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf6ff9b8",
   "metadata": {},
   "source": [
    "# correct code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6469aad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_in_executor' from 'langchain_core.runnables' (C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain\\document_loaders\\__init__.py:192\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m         AcreomLoader,\n\u001b[0;32m     25\u001b[0m         AirbyteCDKLoader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m         YuqueLoader,\n\u001b[0;32m    190\u001b[0m     )\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blob, BlobLoader\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# For backwards compatibility\u001b[39;00m\n\u001b[0;32m    195\u001b[0m _old_to_new_name \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPagedPDFSplitter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyPDFLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelegramChatLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTelegramChatFileLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseBlobParser, BaseLoader\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblob_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Blob, BlobLoader, PathLike\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseBlobParser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPathLike\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, AsyncIterator, Iterator, List, Optional\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocuments\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_in_executor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextSplitter\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'run_in_executor' from 'langchain_core.runnables' (C:\\Users\\murugan\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF document\n",
    "loader = PyPDFLoader(\"C:/Users/murugan/Downloads/Muthukumar.pdf\")\n",
    "pages_content = loader.load_and_split()\n",
    "\n",
    "# Define the text splitter with chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# Split the documents into chunks\n",
    "documents = text_splitter.split_documents(pages_content)\n",
    "\n",
    "# Initialize the embeddings model\n",
    "ollama_emb = OllamaEmbeddings(model=\"llama3\")\n",
    "\n",
    "# Create the FAISS vector store\n",
    "vector = FAISS.from_documents(documents, ollama_emb)\n",
    "\n",
    "# Create the retriever\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Define the system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Only send me the default answer.\"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the document chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the retrieval chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d34d7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(llm=llm, max_buffer_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3635339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3670b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "986f1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion= ConversationChain(llm=llm,memory=memory,metadata=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "814e2077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd267e1f41542aa969d8ce2bd38819f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ddcafdfe7a4afc9808686e273dd4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d2131a209496cba0a009324633305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a0296395f54534b108d30e382bc8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98dc8331131439089041d410feb501a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help! You're asking about the name of a candidate, are you looking for information on a specific election or trying to learn more about someone who's running? I can provide context on various candidates from different political parties and offices. \\n\\nWould you like me to give you a list of current or recent candidates, or perhaps help you find information on a specific individual?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion.predict(input= \"name of the candidate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c95ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21c2733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Muthukumar R.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"name of the candidate?\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349a60f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rmuthukumar0908@gmail.com'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"send me the mailId?\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb568d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a comprehensive list of educational qualifications:\\n\\n1. Bachelor's in science - BSC (MATHEMATICS)\\n\\t* Name of the college or university: Aditanar College of Arts and Science\\n\\t* Group or major: Mathematics\\n2. Master's in science - MSC (MATHEMATICS)\\n\\t* Name of the college or university: Bharathiar University\\n\\t* Group or major: Mathematics\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"send me in list  the edication qualification only in all collage name and group?\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f808685d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"\"\"\n",
    "1. Name of the qualification (e.g., Bachelor's, Master's, Diploma, etc.)\n",
    "2. Name of the college or university\n",
    "3. Group or major (e.g., Computer Science, Business Administration, etc.)\n",
    "\"\"\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00f1629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is the default answer:\\n\\n1. Master's\\n2. Bharathiar University\\n3. MSC (MATHEMATICS)\\n\\nLet me know if you need anything else!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"\"\"\n",
    "1. Name of the qualification (e.g., Bachelor's, Master's, Diploma, etc.)\n",
    "2. Name of the college or university\n",
    "3. Group or major (e.g., Computer Science, Business Administration, etc.)\n",
    "SEND ME THE ANSWER ,the answer provide in list?\n",
    "\"\"\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8dfe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6498c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #first step\n",
    "pages_content = loader.load_and_split()\n",
    "loader= PyPDFLoader( \"C:/Users/murugan/Downloads/Muthukumar.pdf\")\n",
    "#second step\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=\"llama3\",)\n",
    "vector = FAISS.from_documents(pages_content,ollama_emb)\n",
    "retriever=vector.as_retriever()\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d5d092e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The name of the candidate is Muthukumar R.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What is name of the candidate?\"})\n",
    "response.\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ddf99c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know the answer to this question.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"only name\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cf634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3a7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# model_local = ChatOllama(model=\"llama3\")\n",
    "#first step\n",
    "pdf_path = \"C:/Users/murugan/Downloads/Muthukumar.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "documents = text_splitter.split_text(pdf_text)\n",
    "langchain_documents = [Document(page_content=doc) for doc in documents]\n",
    "# langchain_documents = documents\n",
    "#second step\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=\"llama3\",)\n",
    "# vector = ollama_emb.embed_documents(langchain_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcb5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d33c84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306edc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = ollama_emb.embed_documents(langchain_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53fc972",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a FAISS vector store instance and add the embedded documents to it\n",
    "vector = FAISS.from_documents(langchain_documents,ollama_emb)\n",
    "\n",
    "# # Add the embedded documents to the vector store\n",
    "# vector_store.add_documents(documents=langchain_documents, embeddings=vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959d35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c54caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe28d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_txt = input(\"Please enter your queries here... \")\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "{context}\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\":\"\"\"\n",
    "\n",
    "### Personal Information\n",
    "1. Can you confirm your full name?\n",
    "2. What is your current address?\n",
    "3. How can we contact you? Could you provide your phone number and email address?\n",
    "4. Do you have a professional online presence, such as a LinkedIn profile or a personal portfolio website?\n",
    "\n",
    "### Objective or Summary\n",
    "5. Can you summarize your professional background and career goals?\n",
    "6. What are you looking to achieve in your next role?\n",
    "\n",
    "### Education\n",
    "7. Where did you complete your highest level of education?\n",
    "8. What degree(s) have you earned, and in what field(s) of study?\n",
    "9. Can you list any relevant coursework or academic projects?\n",
    "10. Have you received any academic honors or awards?\n",
    "\n",
    "### Certifications and Courses\n",
    "11. Have you completed any certifications related to your field?\n",
    "12. Can you detail any professional courses or training programs you have attended?\n",
    "\n",
    "### Technical Skills\n",
    "13. What programming languages are you proficient in?\n",
    "14. Can you list any software, tools, or technologies you are skilled in?\n",
    "15. How do you stay updated with new technologies in your field?\n",
    "\n",
    "### Work Experience\n",
    "16. Can you describe your most recent job role and responsibilities?\n",
    "17. What were your key achievements or contributions in your previous roles?\n",
    "18. How have you managed or led projects or teams?\n",
    "19. Can you provide examples of how you solved a significant problem at work?\n",
    "20. How did you contribute to your previous company's goals or bottom line?\n",
    "\n",
    "### Projects\n",
    "21. Can you describe a project you are particularly proud of?\n",
    "22. What was your role in this project, and what were the outcomes?\n",
    "23. How did you handle challenges or setbacks during the project?\n",
    "24. What technologies or tools did you use for this project?\n",
    "\n",
    "### Internships\n",
    "25. Where did you complete your internships, and what were your responsibilities?\n",
    "26. How did these internships prepare you for your current role?\n",
    "\n",
    "### Volunteer Experience\n",
    "27. Have you participated in any volunteer work or community service?\n",
    "28. How has your volunteer experience influenced your professional life?\n",
    "\n",
    "### Achievements and Awards\n",
    "29. Can you list any professional awards or recognitions you have received?\n",
    "30. What achievements are you most proud of?\n",
    "\n",
    "### Languages\n",
    "31. What languages do you speak, and how proficient are you in each?\n",
    "\n",
    "### Personal Projects and Hobbies\n",
    "32. Do you have any personal projects or hobbies that relate to your professional skills?\n",
    "33. How do these projects or hobbies enhance your work performance?\n",
    "\n",
    "### References\n",
    "34. Can you provide professional references who can vouch for your work?\n",
    "35. How do you know these references, and what was your working relationship with them?\"\"\"})\n",
    "# print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7341db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I'll answer the questions:\n",
      "\n",
      "### Personal Information\n",
      "\n",
      "1. Full name: Muthukumar R.\n",
      "2. Current address: Tuticorin, Tamil Nadu.\n",
      "3. Contact information: Phone number - 8608764279, Email address - rmuthukumar0908@gmail.com\n",
      "4. Professional online presence: LinkedIn profile and a portfolio website.\n",
      "\n",
      "### Objective or Summary\n",
      "\n",
      "5. Professional background: Aspiring SQL Developer with a strong foundation in database management and data manipulation.\n",
      "6. Career goals: Seeking an entry-level SQL Developer role to apply academic knowledge and contribute to innovative, data-driven projects.\n",
      "\n",
      "### Education\n",
      "\n",
      "7. Highest level of education: Masters in Science (MSC) - Mathematics from Bharathiar University.\n",
      "8. Degree(s) earned: MSC in Mathematics.\n",
      "9. Relevant coursework: Statistical Analysis, Data Analytics in Python.\n",
      "\n",
      "### Certifications and Courses\n",
      "\n",
      "10. Certifications: Master Data Science Program from GUVI IIT-M, Data Analytics and Visualization Job Simulation from Accenture, and MYSQL certification from HackerRank.\n",
      "\n",
      "11. Professional courses or training programs attended: Advanced Programming Professional & Master Data Science from GUVI IIT-M.\n",
      "\n",
      "### Technical Skills\n",
      "\n",
      "12. Programming languages: Python.\n",
      "13. Software, tools, or technologies skilled in: Jupyter Notebooks, GitHub, Streamlit, VS code; Matplotlib, Seaborn, Plotly (Python); Pandas, NumPy, Exploratory Data Analysis (EDA); MySQL, MongoDB.\n",
      "\n",
      "### Work Experience\n",
      "\n",
      "14. Most recent job role and responsibilities: Python Developer at DGI Worx.\n",
      "15. Key achievements or contributions in previous roles: Streamlined web scraping processes, reducing manual effort by 60%.\n",
      "\n",
      "### Projects\n",
      "\n",
      "16. Proud project: YouTube Data Harvesting and Warehousing - retrieved data from YouTube API, stored data in MongoDB, migrated to SQL warehouse, and visualized results in Streamlit.\n",
      "\n",
      "17. Role in the project: Developed a Streamlit UI.\n",
      "18. Outcomes: Improved data retrieval efficiency by 40%.\n",
      "\n",
      "### Achievements and Awards\n",
      "\n",
      "19. Professional awards or recognitions received: None mentioned.\n",
      "20. Most proud of: Achieving 85% accuracy in sales predictions with the Final Retail Sales Forecast project.\n",
      "\n",
      "Let me know if you'd like me to answer more questions!\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d7800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\":\"send me the linked in link?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b494d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help! Unfortunately, based on the provided context, I don't see a LinkedIn link or any information that would allow me to share one with you. The profile doesn't include a LinkedIn link, and there's no other indication of where their LinkedIn page might be.\n",
      "\n",
      "However, if you'd like to contact this individual, you could try reaching out through their email address (rmuthukumar0908@gmail.com) or trying to find them on GitHub (their username is not provided).\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edd5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57c5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c63ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_txt='provide a relevant answer directly and precisely.'\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"hi you name is muthu Ai bot\n",
    "\n",
    "User query:{context}\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "while True:\n",
    "    input_txt = input(\"Please enter your queries here... \")\n",
    "    if input_txt.lower() in ['exit', 'quit']:\n",
    "        print(\"Exiting the chat.\")\n",
    "        break\n",
    "    response = retrieval_chain.invoke({\"input\": input_txt, \"context\": context_txt})\n",
    "    response = get_response(input_txt, context_manager.get_context())\n",
    "    \n",
    "    # Update context with current response\n",
    "    context_manager.update_context(response)\n",
    "    print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ae180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9491ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
